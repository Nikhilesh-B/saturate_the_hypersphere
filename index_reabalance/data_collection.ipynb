{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MSCI additions â€” data collection\n",
        "Fetch Polygon daily bars for MSCI additions and cache to parquet.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from pathlib import Path\n",
        "import keys\n",
        "\n",
        "PG_KEY = getattr(keys, \"PG_KEY\", None)\n",
        "if not PG_KEY:\n",
        "    raise ValueError(\"Polygon API key missing; set PG_KEY in keys.py\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load factors and MSCI additions (dates for windows)\n",
        "FF5 = pd.read_csv('F-F_Research_Data_5_Factors_2x3_daily.csv')\n",
        "FF5['Date'] = pd.to_datetime(FF5['Date'], format=\"%Y%m%d\")\n",
        "FF5 = FF5.set_index('Date').dropna()\n",
        "FF5 /= 100\n",
        "\n",
        "adds_MSCI = pd.read_csv('msci_additions.csv')\n",
        "adds_MSCI['Announcement Date'] = pd.to_datetime(adds_MSCI['Announcement Date'])\n",
        "adds_MSCI['Effective Date'] = pd.to_datetime(adds_MSCI['Effective Date'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Polygon helpers\n",
        "\n",
        "def fetch_polygon_daily(symbol: str, start: str, end: str, adjusted: bool = True, api_key: str = None):\n",
        "    key = api_key or PG_KEY\n",
        "    url = f\"https://api.polygon.io/v2/aggs/ticker/{symbol}/range/1/day/{start}/{end}\"\n",
        "    params = {\"adjusted\": str(adjusted).lower(), \"sort\": \"asc\", \"limit\": 50000, \"apiKey\": key}\n",
        "    r = requests.get(url, params=params, timeout=30)\n",
        "    r.raise_for_status()\n",
        "    rows = r.json().get(\"results\", []) or []\n",
        "    if not rows:\n",
        "        return pd.DataFrame()\n",
        "    df = pd.DataFrame(rows)\n",
        "    df['Date'] = pd.to_datetime(df['t'], unit='ms')\n",
        "    df = df.rename(columns={'o': 'Open', 'h': 'High', 'l': 'Low', 'c': 'Close', 'v': 'Volume'})\n",
        "    return df.set_index('Date').sort_index()\n",
        "\n",
        "\n",
        "def fetch_polygon_window(additions_df: pd.DataFrame, days_back: int = 365, delay_sec: float = 0):\n",
        "    data = {}\n",
        "    frames = []\n",
        "    for _, row in additions_df.iterrows():\n",
        "        ticker = row['Ticker']\n",
        "        announce = row['Announcement Date']\n",
        "        effective = row['Effective Date']\n",
        "        start_date = (min(announce, effective) - pd.Timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
        "        end_date = effective.strftime('%Y-%m-%d')\n",
        "        try:\n",
        "            df = fetch_polygon_daily(ticker, start_date, end_date, adjusted=True)\n",
        "            if df.empty:\n",
        "                print(f\"No data for {ticker} ({start_date} to {end_date})\")\n",
        "                time.sleep(delay_sec)\n",
        "                continue\n",
        "            df['Return'] = df['Close'].pct_change()\n",
        "            data[ticker] = df\n",
        "            tmp = df.reset_index()\n",
        "            tmp['Ticker'] = ticker\n",
        "            tmp = tmp.set_index(['Ticker', 'Date']).sort_index()\n",
        "            frames.append(tmp)\n",
        "            print(f\"Fetched {ticker}: {len(df)} rows\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error fetching {ticker}: {e}\")\n",
        "        finally:\n",
        "            time.sleep(delay_sec)\n",
        "    combined = pd.concat(frames) if frames else pd.DataFrame()\n",
        "    return data, combined\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Fetch Polygon prices\n",
        "Pull ~1 year of data before announcement/effective dates.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fetched NBIS: 265 rows\n",
            "No data for CWV (2024-11-05 to 2025-11-25)\n",
            "Fetched INSM: 265 rows\n",
            "Fetched RKLB: 264 rows\n",
            "Fetched SOFI: 264 rows\n",
            "Fetched AFRM: 264 rows\n",
            "Fetched RYAAY: 263 rows\n",
            "Fetched UAL: 263 rows\n",
            "Fetched RDDT: 236 rows\n",
            "Fetched NTRA: 263 rows\n",
            "Fetched MSTR: 264 rows\n",
            "Fetched PSTG: 264 rows\n",
            "Fetched VST: 263 rows\n",
            "Fetched EME: 263 rows\n",
            "Fetched SMCI: 263 rows\n",
            "Fetched DECK: 263 rows\n",
            "Fetched BLDR: 265 rows\n",
            "Fetched HUBS: 265 rows\n",
            "Fetched RIVN: 266 rows\n",
            "Fetched WBD: 162 rows\n",
            "Fetched GFS: 148 rows\n",
            "Fetched ABNB: 245 rows\n",
            "Fetched LCID: 90 rows\n",
            "Fetched SNOW: 118 rows\n",
            "Fetched DASH: 117 rows\n",
            "Fetched PLTR: 55 rows\n",
            "Error fetching ZM: 403 Client Error: Forbidden for url: https://api.polygon.io/v2/aggs/ticker/ZM/range/1/day/2019-11-11/2020-11-30?adjusted=true&sort=asc&limit=50000&apiKey=ztqNuAs14idakc5AOJbafSLh4kcZhpkV\n",
            "Error fetching MRNA: 403 Client Error: Forbidden for url: https://api.polygon.io/v2/aggs/ticker/MRNA/range/1/day/2019-08-13/2020-08-31?adjusted=true&sort=asc&limit=50000&apiKey=ztqNuAs14idakc5AOJbafSLh4kcZhpkV\n",
            "Error fetching PTON: 403 Client Error: Forbidden for url: https://api.polygon.io/v2/aggs/ticker/PTON/range/1/day/2019-08-13/2020-08-31?adjusted=true&sort=asc&limit=50000&apiKey=ztqNuAs14idakc5AOJbafSLh4kcZhpkV\n",
            "Combined rows: 5658\n"
          ]
        }
      ],
      "source": [
        "polygon_data, polygon_prices = fetch_polygon_window(adds_MSCI, days_back=365, delay_sec=0)\n",
        "print(f\"Combined rows: {len(polygon_prices)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Cache to parquet\n",
        "Save MultiIndex `polygon_prices` for reuse in analysis.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved to polygon_prices.parquet (rows=5658)\n"
          ]
        }
      ],
      "source": [
        "prices_path = Path('polygon_prices.parquet')\n",
        "polygon_prices.to_parquet(prices_path)\n",
        "print(f\"Saved to {prices_path} (rows={len(polygon_prices)})\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
