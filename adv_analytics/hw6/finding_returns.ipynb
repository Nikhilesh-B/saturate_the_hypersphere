{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2: Predicting Stock Returns\n",
    "\n",
    "We aim to predict the direction of next month's return ($y_{t+1}^i$) using current month's characteristics ($X_t^i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cf/zk37hd_50bv_nlrdlxrb4q3r0000gn/T/ipykernel_16089/1605797025.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['dates'] = pd.to_datetime(df['dates'])\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dates</th>\n",
       "      <th>cusip</th>\n",
       "      <th>Price</th>\n",
       "      <th>MV</th>\n",
       "      <th>M2B</th>\n",
       "      <th>S2A</th>\n",
       "      <th>SD2A</th>\n",
       "      <th>LD2A</th>\n",
       "      <th>PE</th>\n",
       "      <th>Sales</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48449</th>\n",
       "      <td>190814</td>\n",
       "      <td>2009-11-30</td>\n",
       "      <td>125581</td>\n",
       "      <td>28.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.657499</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.125728</td>\n",
       "      <td>0.904575</td>\n",
       "      <td>3.736130</td>\n",
       "      <td>745.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48450</th>\n",
       "      <td>190815</td>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>125581</td>\n",
       "      <td>27.61</td>\n",
       "      <td>5522000.00</td>\n",
       "      <td>0.657499</td>\n",
       "      <td>0.015832</td>\n",
       "      <td>0.125728</td>\n",
       "      <td>0.904575</td>\n",
       "      <td>3.736130</td>\n",
       "      <td>745.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48451</th>\n",
       "      <td>190816</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>125581</td>\n",
       "      <td>31.82</td>\n",
       "      <td>6364000.00</td>\n",
       "      <td>0.913891</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.096820</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>56.463768</td>\n",
       "      <td>1753.2</td>\n",
       "      <td>0.152481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48452</th>\n",
       "      <td>190817</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>125581</td>\n",
       "      <td>36.43</td>\n",
       "      <td>7287311.48</td>\n",
       "      <td>0.913891</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.096820</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>56.463768</td>\n",
       "      <td>1753.2</td>\n",
       "      <td>0.144877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48453</th>\n",
       "      <td>190818</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>125581</td>\n",
       "      <td>38.96</td>\n",
       "      <td>7793402.56</td>\n",
       "      <td>0.913891</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.096820</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>56.463768</td>\n",
       "      <td>1753.2</td>\n",
       "      <td>0.069448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      dates   cusip  Price          MV       M2B       S2A  \\\n",
       "48449      190814 2009-11-30  125581  28.99         NaN  0.657499  0.015832   \n",
       "48450      190815 2009-12-31  125581  27.61  5522000.00  0.657499  0.015832   \n",
       "48451      190816 2010-01-29  125581  31.82  6364000.00  0.913891  0.043960   \n",
       "48452      190817 2010-02-26  125581  36.43  7287311.48  0.913891  0.043960   \n",
       "48453      190818 2010-03-31  125581  38.96  7793402.56  0.913891  0.043960   \n",
       "\n",
       "           SD2A      LD2A         PE   Sales       RET  \n",
       "48449  0.125728  0.904575   3.736130   745.0       NaN  \n",
       "48450  0.125728  0.904575   3.736130   745.0       NaN  \n",
       "48451  0.096820  0.940486  56.463768  1753.2  0.152481  \n",
       "48452  0.096820  0.940486  56.463768  1753.2  0.144877  \n",
       "48453  0.096820  0.940486  56.463768  1753.2  0.069448  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('Data_Pred_Return.csv')\n",
    "df['dates'] = pd.to_datetime(df['dates'])\n",
    "df = df.sort_values(['cusip', 'dates'])\n",
    "\n",
    "# Inspect data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (a): Feature Construction\n",
    "\n",
    "We need to select features that are stationary to avoid spurious regression results. \n",
    "\n",
    "**Variable Analysis:**\n",
    "- **Non-Stationary (Trends):** `Price`, `MV` (Market Value), `Sales`. These variables tend to grow over time and should not be used directly in levels. We will transform them into growth rates (percentage change) to make them stationary.\n",
    "- **Stationary (Ratios/Returns):** `M2B` (Market-to-Book), `S2A` (Sales-to-Asset), `SD2A` (Short-term Debt-to-Asset), `LD2A` (Long-term Debt-to-Asset), `PE` (Price-to-Earnings), `RET` (Returns).\n",
    "\n",
    "**Selected Features:**\n",
    "We will use the provided financial ratios, the current month's return (Momentum), and the growth rates of the non-stationary variables as predictors.\n",
    "\n",
    "- `M2B`\n",
    "- `S2A`\n",
    "- `SD2A`\n",
    "- `LD2A`\n",
    "- `PE`\n",
    "- `RET` (Current month return $r_t$)\n",
    "- `Price_Growth`\n",
    "- `MV_Growth`\n",
    "- `Sales_Growth`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (49032, 17), Clean shape: (41795, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cf/zk37hd_50bv_nlrdlxrb4q3r0000gn/T/ipykernel_16089/2971208309.py:4: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df['MV_Growth'] = df.groupby('cusip')['MV'].pct_change()\n",
      "/var/folders/cf/zk37hd_50bv_nlrdlxrb4q3r0000gn/T/ipykernel_16089/2971208309.py:5: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  df['Sales_Growth'] = df.groupby('cusip')['Sales'].pct_change()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>dates</th>\n",
       "      <th>cusip</th>\n",
       "      <th>Price</th>\n",
       "      <th>MV</th>\n",
       "      <th>M2B</th>\n",
       "      <th>S2A</th>\n",
       "      <th>SD2A</th>\n",
       "      <th>LD2A</th>\n",
       "      <th>PE</th>\n",
       "      <th>Sales</th>\n",
       "      <th>RET</th>\n",
       "      <th>Price_Growth</th>\n",
       "      <th>MV_Growth</th>\n",
       "      <th>Sales_Growth</th>\n",
       "      <th>Next_RET</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48451</th>\n",
       "      <td>190816</td>\n",
       "      <td>2010-01-29</td>\n",
       "      <td>125581</td>\n",
       "      <td>31.82</td>\n",
       "      <td>6364000.00</td>\n",
       "      <td>0.913891</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.096820</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>56.463768</td>\n",
       "      <td>1753.2</td>\n",
       "      <td>0.152481</td>\n",
       "      <td>0.152481</td>\n",
       "      <td>0.152481</td>\n",
       "      <td>1.353289</td>\n",
       "      <td>0.144877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48452</th>\n",
       "      <td>190817</td>\n",
       "      <td>2010-02-26</td>\n",
       "      <td>125581</td>\n",
       "      <td>36.43</td>\n",
       "      <td>7287311.48</td>\n",
       "      <td>0.913891</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.096820</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>56.463768</td>\n",
       "      <td>1753.2</td>\n",
       "      <td>0.144877</td>\n",
       "      <td>0.144877</td>\n",
       "      <td>0.145084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48453</th>\n",
       "      <td>190818</td>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>125581</td>\n",
       "      <td>38.96</td>\n",
       "      <td>7793402.56</td>\n",
       "      <td>0.913891</td>\n",
       "      <td>0.043960</td>\n",
       "      <td>0.096820</td>\n",
       "      <td>0.940486</td>\n",
       "      <td>56.463768</td>\n",
       "      <td>1753.2</td>\n",
       "      <td>0.069448</td>\n",
       "      <td>0.069448</td>\n",
       "      <td>0.069448</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042094</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48454</th>\n",
       "      <td>190819</td>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>125581</td>\n",
       "      <td>40.60</td>\n",
       "      <td>8121542.80</td>\n",
       "      <td>0.785494</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.093724</td>\n",
       "      <td>0.962398</td>\n",
       "      <td>42.325000</td>\n",
       "      <td>1780.7</td>\n",
       "      <td>0.042094</td>\n",
       "      <td>0.042094</td>\n",
       "      <td>0.042105</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>-0.093842</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48455</th>\n",
       "      <td>190820</td>\n",
       "      <td>2010-05-28</td>\n",
       "      <td>125581</td>\n",
       "      <td>36.79</td>\n",
       "      <td>7359434.81</td>\n",
       "      <td>0.785494</td>\n",
       "      <td>0.049133</td>\n",
       "      <td>0.093724</td>\n",
       "      <td>0.962398</td>\n",
       "      <td>42.325000</td>\n",
       "      <td>1780.7</td>\n",
       "      <td>-0.093842</td>\n",
       "      <td>-0.093842</td>\n",
       "      <td>-0.093838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.079641</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      dates   cusip  Price          MV       M2B       S2A  \\\n",
       "48451      190816 2010-01-29  125581  31.82  6364000.00  0.913891  0.043960   \n",
       "48452      190817 2010-02-26  125581  36.43  7287311.48  0.913891  0.043960   \n",
       "48453      190818 2010-03-31  125581  38.96  7793402.56  0.913891  0.043960   \n",
       "48454      190819 2010-04-30  125581  40.60  8121542.80  0.785494  0.049133   \n",
       "48455      190820 2010-05-28  125581  36.79  7359434.81  0.785494  0.049133   \n",
       "\n",
       "           SD2A      LD2A         PE   Sales       RET  Price_Growth  \\\n",
       "48451  0.096820  0.940486  56.463768  1753.2  0.152481      0.152481   \n",
       "48452  0.096820  0.940486  56.463768  1753.2  0.144877      0.144877   \n",
       "48453  0.096820  0.940486  56.463768  1753.2  0.069448      0.069448   \n",
       "48454  0.093724  0.962398  42.325000  1780.7  0.042094      0.042094   \n",
       "48455  0.093724  0.962398  42.325000  1780.7 -0.093842     -0.093842   \n",
       "\n",
       "       MV_Growth  Sales_Growth  Next_RET  Target  \n",
       "48451   0.152481      1.353289  0.144877       1  \n",
       "48452   0.145084      0.000000  0.069448       1  \n",
       "48453   0.069448      0.000000  0.042094       1  \n",
       "48454   0.042105      0.015686 -0.093842       0  \n",
       "48455  -0.093838      0.000000 -0.079641       0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform non-stationary variables\n",
    "# We use pct_change() within each group to get the growth rate\n",
    "df['Price_Growth'] = df.groupby('cusip')['Price'].pct_change()\n",
    "df['MV_Growth'] = df.groupby('cusip')['MV'].pct_change()\n",
    "df['Sales_Growth'] = df.groupby('cusip')['Sales'].pct_change()\n",
    "\n",
    "# Define predictors\n",
    "features = ['M2B', 'S2A', 'SD2A', 'LD2A', 'PE', 'RET', 'Price_Growth', 'MV_Growth', 'Sales_Growth']\n",
    "\n",
    "# Create Target: y_{t+1} = 1 if r_{t+1} > 0 else 0\n",
    "# We group by cusip and shift the 'RET' column UP by 1 (-1) to get the next month's return aligned with current row\n",
    "df['Next_RET'] = df.groupby('cusip')['RET'].shift(-1)\n",
    "\n",
    "# Create binary target\n",
    "df['Target'] = (df['Next_RET'] > 0).astype(int)\n",
    "\n",
    "# Replace infinity with NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Remove rows with NaN (last month for each stock has no next return, and first month for growth rates)\n",
    "df_clean = df.dropna(subset=['Next_RET'] + features).copy()\n",
    "\n",
    "# Verify shape\n",
    "print(f\"Original shape: {df.shape}, Clean shape: {df_clean.shape}\")\n",
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (b): Logistic Regression\n",
    "\n",
    "We split the data into Training (1989-2011) and Testing (Post 2011, i.e., 2012-2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples: 29092, Test samples: 12703\n",
      "Logistic Regression Coefficients:\n",
      "M2B             0.104969\n",
      "S2A             0.008219\n",
      "SD2A           -0.002737\n",
      "LD2A           -0.003609\n",
      "PE              0.004068\n",
      "RET            -0.045293\n",
      "Price_Growth    0.026254\n",
      "MV_Growth       0.030867\n",
      "Sales_Growth   -0.003483\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "train_mask = (df_clean['dates'].dt.year >= 1989) & (df_clean['dates'].dt.year <= 2011)\n",
    "test_mask = (df_clean['dates'].dt.year > 2011)\n",
    "\n",
    "X_train = df_clean.loc[train_mask, features]\n",
    "y_train = df_clean.loc[train_mask, 'Target']\n",
    "\n",
    "X_test = df_clean.loc[test_mask, features]\n",
    "y_test = df_clean.loc[test_mask, 'Target']\n",
    "\n",
    "print(f\"Train samples: {len(X_train)}, Test samples: {len(X_test)}\")\n",
    "\n",
    "# Standardize features (Important for Logistic Regression and Regularization)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Fit Logistic Regression (No penalty initially or weak penalty default l2)\n",
    "# The problem asks for standard Logistic Regression first.\n",
    "logit_model = LogisticRegression(penalty=None, max_iter=1000) \n",
    "# Note: penalty='none' is deprecated in newer sklearn versions, use penalty=None. If older sklearn, use penalty='none'.\n",
    "# If 'penalty=None' fails, I will fallback to a very large C.\n",
    "try:\n",
    "    logit_model.fit(X_train_scaled, y_train)\n",
    "except:\n",
    "    logit_model = LogisticRegression(C=1e9, max_iter=1000) # Effectively no penalty\n",
    "    logit_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Logistic Regression Coefficients:\")\n",
    "print(pd.Series(logit_model.coef_[0], index=features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (c): Ridge and LASSO with Time-Series Cross Validation\n",
    "\n",
    "We will use `LogisticRegressionCV` which supports time-series cross-validation steps if configured, or we can manually implement GridSearch with `TimeSeriesSplit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting Ridge (L2)...\n",
      "Best C for Ridge: 0.000774263682681127\n",
      "Fitting LASSO (L1)...\n",
      "Best C for LASSO: 0.046415888336127774\n",
      "\n",
      "Ridge Coefficients:\n",
      "M2B             0.078217\n",
      "S2A             0.006966\n",
      "SD2A           -0.002480\n",
      "LD2A           -0.003028\n",
      "PE              0.005493\n",
      "RET            -0.027132\n",
      "Price_Growth    0.018073\n",
      "MV_Growth       0.021840\n",
      "Sales_Growth   -0.002850\n",
      "dtype: float64\n",
      "\n",
      "LASSO Coefficients:\n",
      "M2B             0.099209\n",
      "S2A             0.004079\n",
      "SD2A            0.000000\n",
      "LD2A            0.000000\n",
      "PE              0.000654\n",
      "RET            -0.033995\n",
      "Price_Growth    0.018667\n",
      "MV_Growth       0.025723\n",
      "Sales_Growth   -0.000485\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Define TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "# Ridge (L2 Penalty)\n",
    "print(\"Fitting Ridge (L2)...\")\n",
    "ridge_cv = LogisticRegressionCV(\n",
    "    Cs=10, \n",
    "    penalty='l2', \n",
    "    cv=tscv, \n",
    "    solver='lbfgs', \n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "ridge_cv.fit(X_train_scaled, y_train)\n",
    "print(f\"Best C for Ridge: {ridge_cv.C_[0]}\")\n",
    "\n",
    "# LASSO (L1 Penalty)\n",
    "print(\"Fitting LASSO (L1)...\")\n",
    "lasso_cv = LogisticRegressionCV(\n",
    "    Cs=10, \n",
    "    penalty='l1', \n",
    "    cv=tscv, \n",
    "    solver='liblinear', \n",
    "    max_iter=1000,\n",
    "    random_state=42\n",
    ")\n",
    "lasso_cv.fit(X_train_scaled, y_train)\n",
    "print(f\"Best C for LASSO: {lasso_cv.C_[0]}\")\n",
    "\n",
    "print(\"\\nRidge Coefficients:\")\n",
    "print(pd.Series(ridge_cv.coef_[0], index=features))\n",
    "\n",
    "print(\"\\nLASSO Coefficients:\")\n",
    "print(pd.Series(lasso_cv.coef_[0], index=features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (d): Confusion Matrix and Error Rates\n",
    "\n",
    "We construct the confusion matrix for the **test sample** (Post 2011) with cutoff $\\bar{p} = 0.5$.\n",
    "We compute:\n",
    "- **Type I Error Rate (False Positive Rate):** Proportion of actual 0s classified as 1. $P(\\hat{y}=1 | y=0)$.\n",
    "- **Type II Error Rate (False Negative Rate):** Proportion of actual 1s classified as 0. $P(\\hat{y}=0 | y=1)$.\n",
    "- **Overall Error Rate:** Proportion of incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Standard Logit ---\n",
      "Confusion Matrix:\n",
      "[[   0 5363]\n",
      " [   0 7340]]\n",
      "Type I Error Rate (FP Rate): 1.0000\n",
      "Type II Error Rate (FN Rate): 0.0000\n",
      "Overall Error Rate: 0.4222\n",
      "------------------------------\n",
      "--- Ridge Logit ---\n",
      "Confusion Matrix:\n",
      "[[   0 5363]\n",
      " [   0 7340]]\n",
      "Type I Error Rate (FP Rate): 1.0000\n",
      "Type II Error Rate (FN Rate): 0.0000\n",
      "Overall Error Rate: 0.4222\n",
      "------------------------------\n",
      "--- LASSO Logit ---\n",
      "Confusion Matrix:\n",
      "[[   0 5363]\n",
      " [   0 7340]]\n",
      "Type I Error Rate (FP Rate): 1.0000\n",
      "Type II Error Rate (FN Rate): 0.0000\n",
      "Overall Error Rate: 0.4222\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "def compute_metrics(model, X, y_true, model_name=\"Model\"):\n",
    "    y_pred = model.predict(X)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # Error Rates\n",
    "    type1_error = fp / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    type2_error = fn / (fn + tp) if (fn + tp) > 0 else 0\n",
    "    overall_error = (fp + fn) / (tn + fp + fn + tp)\n",
    "    \n",
    "    print(f\"--- {model_name} ---\")\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(f\"Type I Error Rate (FP Rate): {type1_error:.4f}\")\n",
    "    print(f\"Type II Error Rate (FN Rate): {type2_error:.4f}\")\n",
    "    print(f\"Overall Error Rate: {overall_error:.4f}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# Evaluate models on Test Set\n",
    "compute_metrics(logit_model, X_test_scaled, y_test, \"Standard Logit\")\n",
    "compute_metrics(ridge_cv, X_test_scaled, y_test, \"Ridge Logit\")\n",
    "compute_metrics(lasso_cv, X_test_scaled, y_test, \"LASSO Logit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (e): Random Forest\n",
    "\n",
    "We implement a Random Forest model and compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Random Forest ---\n",
      "Confusion Matrix:\n",
      "[[1640 3723]\n",
      " [2108 5232]]\n",
      "Type I Error Rate (FP Rate): 0.6942\n",
      "Type II Error Rate (FN Rate): 0.2872\n",
      "Overall Error Rate: 0.4590\n",
      "------------------------------\n",
      "Feature Importances:\n",
      "MV_Growth       0.127728\n",
      "PE              0.124103\n",
      "M2B             0.123992\n",
      "RET             0.122849\n",
      "Price_Growth    0.122179\n",
      "S2A             0.120274\n",
      "LD2A            0.101579\n",
      "SD2A            0.090095\n",
      "Sales_Growth    0.067201\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Fit Random Forest\n",
    "# Using a reasonable number of estimators and random_state for reproducibility\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Random Forest\n",
    "compute_metrics(rf_model, X_test_scaled, y_test, \"Random Forest\")\n",
    "\n",
    "# Feature Importance\n",
    "importances = pd.Series(rf_model.feature_importances_, index=features).sort_values(ascending=False)\n",
    "print(\"Feature Importances:\")\n",
    "print(importances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part (f): Feed-Forward Neural Network (Optional)\n",
    "\n",
    "We implement a simple feed-forward neural network (MLPClassifier) and compare its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Neural Network ---\n",
      "Confusion Matrix:\n",
      "[[ 115 5248]\n",
      " [ 133 7207]]\n",
      "Type I Error Rate (FP Rate): 0.9786\n",
      "Type II Error Rate (FN Rate): 0.0181\n",
      "Overall Error Rate: 0.4236\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Fit Neural Network\n",
    "# Simple architecture: one hidden layer with 100 neurons (default)\n",
    "nn_model = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "nn_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate Neural Network\n",
    "compute_metrics(nn_model, X_test_scaled, y_test, \"Neural Network\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
